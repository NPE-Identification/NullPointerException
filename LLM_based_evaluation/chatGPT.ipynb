{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import logging\n",
    "import time\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configuration\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for NPE classification.\"\"\"\n",
    "    DATA_PATH: str = \"/root/workspace/npe_project/llm/NPEPatches.json\"\n",
    "    OUTPUT_DIR: str = \"results\"\n",
    "    MODEL: str = \"gpt-4o\"\n",
    "    MAX_TOKENS: int = 500\n",
    "    TEMPERATURE: float = 0.1\n",
    "    MAX_RETRIES: int = 3\n",
    "    RETRY_DELAY: float = 5\n",
    "    API_TIMEOUT: float = 30\n",
    "    RATE_LIMIT_DELAY: float = 2\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('npe_classification.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NPEAgent:\n",
    "    \"\"\"Agent for NPE classification using ChatGPT-4o.\"\"\"\n",
    "    \n",
    "    def __init__(self, role: str, prompt: str):\n",
    "        self.role = role\n",
    "        self.prompt = prompt\n",
    "        self.setup_client()\n",
    "    \n",
    "    def setup_client(self) -> None:\n",
    "        \"\"\"Initialize OpenAI client.\"\"\"\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
    "        openai.api_key = api_key\n",
    "    \n",
    "    def process(self, content: Dict[str, Any], \n",
    "                previous_results: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Process content through ChatGPT-4.\"\"\"\n",
    "        for attempt in range(Config.MAX_RETRIES):\n",
    "            try:\n",
    "                if attempt > 0:\n",
    "                    time.sleep(Config.RETRY_DELAY * (2 ** attempt))\n",
    "                \n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": self.prompt},\n",
    "                    {\"role\": \"user\", \"content\": self._format_content(content, previous_results)}\n",
    "                ]\n",
    "                \n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=Config.MODEL,\n",
    "                    messages=messages,\n",
    "                    temperature=Config.TEMPERATURE,\n",
    "                    max_tokens=Config.MAX_TOKENS,\n",
    "                    response_format={\"type\": \"json_object\"}\n",
    "                )\n",
    "                \n",
    "                return json.loads(response.choices[0].message.content)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt == Config.MAX_RETRIES - 1:\n",
    "                    return self._get_default_response(str(e))\n",
    "                time.sleep(Config.RATE_LIMIT_DELAY)\n",
    "    \n",
    "    def _format_content(self, content: Dict[str, Any], \n",
    "                       previous_results: Optional[Dict]) -> str:\n",
    "        \"\"\"Format content for API request.\"\"\"\n",
    "        if previous_results:\n",
    "            return (f\"Previous analysis: {json.dumps(previous_results)}\\n\\n\"\n",
    "                   f\"New content: {json.dumps(content)}\")\n",
    "        return json.dumps(content)\n",
    "    \n",
    "    def _get_default_response(self, reason: str) -> Dict[str, Any]:\n",
    "        \"\"\"Return default response for errors.\"\"\"\n",
    "        return {\n",
    "            \"npe_found\": False,\n",
    "            \"confidence\": 0.0,\n",
    "            \"reasoning\": f\"Error: {reason}\"\n",
    "        }\n",
    "\n",
    "def multi_agent_classify(commit_message: str, patch: str, added_lines: str) -> str:\n",
    "    \"\"\"Perform multi-agent classification of NPE fixes.\"\"\"\n",
    "    try:\n",
    "        # Initialize agents with specialized prompts\n",
    "        detector = NPEAgent(\"detector\", \"\"\"\n",
    "            You are an expert at detecting NullPointerException (NPE) patterns.\n",
    "            Analyze the code changes for NPE-related issues.\n",
    "            Provide your analysis as a JSON with:\n",
    "            {\n",
    "                \"npe_found\": boolean,\n",
    "                \"confidence\": float (0-1),\n",
    "                \"reasoning\": string\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        classifier = NPEAgent(\"classifier\", \"\"\"\n",
    "            You are a code pattern classifier for NPE fixes.\n",
    "            Review the code and previous detection.\n",
    "            Respond with JSON:\n",
    "            {\n",
    "                \"is_npe_fix\": boolean,\n",
    "                \"confidence\": float (0-1),\n",
    "                \"patterns\": array of strings\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        evaluator = NPEAgent(\"evaluator\", \"\"\"\n",
    "            You are a senior code reviewer making final NPE fix determinations.\n",
    "            Review all previous analyses and provide JSON:\n",
    "            {\n",
    "                \"final_decision\": \"NPE-Fixes\" or \"Not-NPE\",\n",
    "                \"confidence\": float (0-1),\n",
    "                \"explanation\": string\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        # Multi-stage analysis\n",
    "        content = {\n",
    "            \"commit_message\": commit_message,\n",
    "            \"patch\": patch,\n",
    "            \"added_lines\": added_lines\n",
    "        }\n",
    "        \n",
    "        detection = detector.process(content)\n",
    "        classification = classifier.process(content, detection)\n",
    "        final_result = evaluator.process(content, {\n",
    "            \"detection\": detection,\n",
    "            \"classification\": classification\n",
    "        })\n",
    "        \n",
    "        return final_result.get(\"final_decision\", \"Not-NPE\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Classification error: {str(e)}\")\n",
    "        return \"Not-NPE\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "        results = {\"y_true\": [], \"y_pred\": [], \"misclassified\": []}\n",
    "        \n",
    "        # Load and process data\n",
    "        with open(Config.DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        logger.info(f\"Processing {len(data)} commits...\")\n",
    "        \n",
    "        for item in tqdm(data, desc=\"Analyzing commits\"):\n",
    "            try:\n",
    "                prediction = multi_agent_classify(\n",
    "                    item.get(\"Commit Message\", \"\"),\n",
    "                    item.get(\"Patch\", \"\"),\n",
    "                    item.get(\"Added Lines\", \"\")\n",
    "                )\n",
    "                \n",
    "                true_label = item[\"Category\"]\n",
    "                results[\"y_true\"].append(true_label)\n",
    "                results[\"y_pred\"].append(prediction)\n",
    "                \n",
    "                if prediction != true_label:\n",
    "                    results[\"misclassified\"].append({\n",
    "                        \"sha\": item.get(\"Commit SHA\", \"Unknown\"),\n",
    "                        \"true_label\": true_label,\n",
    "                        \"predicted\": prediction\n",
    "                    })\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing commit: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate and save metrics\n",
    "        if results[\"y_true\"] and results[\"y_pred\"]:\n",
    "            metrics = calculate_metrics(results[\"y_true\"], results[\"y_pred\"])\n",
    "            save_results(results, metrics, Config.OUTPUT_DIR)\n",
    "            print_metrics(metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
#
