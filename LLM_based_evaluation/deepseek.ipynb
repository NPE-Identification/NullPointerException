{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Groq API client\n",
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For metrics calculation\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For progress bars\n",
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For environment variables\n",
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import logging\n",
    "import time\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('npe_classification.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"/root/workspace/npe_project/llm/NPEPatches.json\"\n",
    "OUTPUT_DIR = \"results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# API Configuration\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 5\n",
    "API_TIMEOUT = 30\n",
    "RATE_LIMIT_DELAY = 2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GROQ_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY environment variable is required\")\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load and validate JSON data from file\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        logger.info(f\"Successfully loaded {len(data)} records from {filepath}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Data file not found: {filepath}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Invalid JSON format in file: {filepath}\")\n",
    "        raise\n",
    "\n",
    "class NPEAgent:\n",
    "    def __init__(self, client, role, prompt):\n",
    "        self.client = client\n",
    "        self.role = role\n",
    "        self.prompt = prompt\n",
    "        self.retry_count = 0\n",
    "    \n",
    "    def process(self, content, previous_results=None):\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                time.sleep(RATE_LIMIT_DELAY)\n",
    "                messages = [{\"role\": \"system\", \"content\": self.prompt}]\n",
    "                user_message = content if not previous_results else \\\n",
    "                    f\"Previous analysis: {json.dumps(previous_results)}\\n\\nNew content: {content}\"\n",
    "                messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "                \n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=\"deepseek-r1-distill-llama-70b\",\n",
    "                    messages=messages,\n",
    "                    temperature=0.1,\n",
    "                    max_tokens=500,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    timeout=API_TIMEOUT\n",
    "                )\n",
    "                \n",
    "                response_text = completion.choices[0].message.content\n",
    "                return json.loads(response_text)\n",
    "                \n",
    "            except JSONDecodeError:\n",
    "                logger.warning(f\"Attempt {attempt + 1}: Invalid JSON from {self.role}\")\n",
    "                if attempt == MAX_RETRIES - 1:\n",
    "                    return self._get_default_response(\"JSON parsing error\")\n",
    "                time.sleep(RETRY_DELAY)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt == MAX_RETRIES - 1:\n",
    "                    return self._get_default_response(f\"Error: {str(e)}\")\n",
    "                time.sleep(RETRY_DELAY)\n",
    "\n",
    "    def _get_default_response(self, reason):\n",
    "        if self.role == \"evaluator\":\n",
    "            return {\n",
    "                \"final_decision\": \"Not-NPE\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"feedback\": reason\n",
    "            }\n",
    "        return {\n",
    "            \"npe_found\": False,\n",
    "            \"confidence\": 0.0,\n",
    "            \"reasoning\": reason\n",
    "        }\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"precision\": precision_score(y_true, y_pred, pos_label=\"NPE-Fixes\"),\n",
    "            \"recall\": recall_score(y_true, y_pred, pos_label=\"NPE-Fixes\"),\n",
    "            \"f1\": f1_score(y_true, y_pred, pos_label=\"NPE-Fixes\"),\n",
    "            \"confusion_matrix\": {\n",
    "                \"true_negatives\": int(tn),\n",
    "                \"false_positives\": int(fp),\n",
    "                \"false_negatives\": int(fn),\n",
    "                \"true_positives\": int(tp)\n",
    "            },\n",
    "            \"fpr\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "            \"fnr\": fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating metrics: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print(\"\\nClassification Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"False Positive Rate: {metrics['fpr']:.4f}\")\n",
    "    print(f\"False Negative Rate: {metrics['fnr']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = metrics['confusion_matrix']\n",
    "    print(f\"True Negatives: {cm['true_negatives']}\")\n",
    "    print(f\"False Positives: {cm['false_positives']}\")\n",
    "    print(f\"False Negatives: {cm['false_negatives']}\")\n",
    "    print(f\"True Positives: {cm['true_positives']}\")\n",
    "\n",
    "def save_results(results, metrics, output_dir):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(output_dir, f\"classification_results_{timestamp}.json\")\n",
    "    \n",
    "    full_results = {\n",
    "        \"metrics\": metrics,\n",
    "        \"misclassified_commits\": results[\"misclassified\"],\n",
    "        \"run_timestamp\": timestamp,\n",
    "        \"total_commits_processed\": len(results[\"y_true\"]),\n",
    "        \"total_misclassified\": len(results[\"misclassified\"])\n",
    "    }\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(full_results, f, indent=2)\n",
    "    logger.info(f\"Results saved to {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def multi_agent_classify(client, commit_message, patch, added_lines):\n",
    "    try:\n",
    "        detector = NPEAgent(client, \"detector\", \"\"\"\n",
    "            You are a specialized NullPointerException (NPE) detector. \n",
    "            Analyze the given code changes and respond with a JSON object containing:\n",
    "            {\n",
    "                \"npe_found\": boolean,\n",
    "                \"confidence\": float between 0-1,\n",
    "                \"reasoning\": string explanation\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        classifier = NPEAgent(client, \"classifier\", \"\"\"\n",
    "            You are a code pattern classifier specializing in NPE fixes.\n",
    "            Analyze the code and respond with a JSON object containing:\n",
    "            {\n",
    "                \"is_npe_fix\": boolean,\n",
    "                \"pattern_match\": float between 0-1,\n",
    "                \"identified_patterns\": array of strings\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        evaluator = NPEAgent(client, \"evaluator\", \"\"\"\n",
    "            You are a senior code reviewer evaluating NPE fix classifications.\n",
    "            Review the analysis and respond with a JSON object containing:\n",
    "            {\n",
    "                \"final_decision\": string (\"NPE-Fixes\" or \"Not-NPE\"),\n",
    "                \"confidence\": float between 0-1,\n",
    "                \"feedback\": string explanation\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        content = json.dumps({\n",
    "            \"commit_message\": commit_message,\n",
    "            \"patch\": patch,\n",
    "            \"added_lines\": added_lines\n",
    "        })\n",
    "        \n",
    "        detection_result = detector.process(content)\n",
    "        if not isinstance(detection_result, dict):\n",
    "            logger.warning(\"Invalid detection result format\")\n",
    "            return \"Not-NPE\"\n",
    "            \n",
    "        classification_result = classifier.process(content, detection_result)\n",
    "        if not isinstance(classification_result, dict):\n",
    "            logger.warning(\"Invalid classification result format\")\n",
    "            return \"Not-NPE\"\n",
    "            \n",
    "        final_result = evaluator.process(content, {\n",
    "            \"detection\": detection_result,\n",
    "            \"classification\": classification_result\n",
    "        })\n",
    "        \n",
    "        if isinstance(final_result, dict) and \"final_decision\" in final_result:\n",
    "            logger.info(f\"Classification confidence: {final_result.get('confidence', 0.0)}\")\n",
    "            return final_result[\"final_decision\"]\n",
    "        return \"Not-NPE\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in multi-agent classification: {str(e)}\")\n",
    "        return \"Not-NPE\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        client = Groq(api_key=api_key)\n",
    "        results = {\"y_true\": [], \"y_pred\": [], \"misclassified\": []}\n",
    "        \n",
    "        data = load_data(DATA_PATH)\n",
    "        total_commits = len(data)\n",
    "        logger.info(f\"Starting processing of {total_commits} commits...\")\n",
    "        \n",
    "        with tqdm(total=total_commits, desc=\"Processing commits\") as pbar:\n",
    "            for idx, item in enumerate(data, 1):\n",
    "                try:\n",
    "                    commit_sha = item.get(\"Commit SHA\", \"Unknown\")\n",
    "                    pbar.set_description(f\"Processing {commit_sha}\")\n",
    "                    \n",
    "                    true_label = item[\"Category\"]\n",
    "                    final_pred = multi_agent_classify(\n",
    "                        client,\n",
    "                        item.get(\"Commit Message\", \"\"),\n",
    "                        item.get(\"Patch\", \"\"),\n",
    "                        item.get(\"Added Lines\", \"\")\n",
    "                    )\n",
    "                    \n",
    "                    results[\"y_true\"].append(true_label)\n",
    "                    results[\"y_pred\"].append(final_pred)\n",
    "                    \n",
    "                    if final_pred != true_label:\n",
    "                        results[\"misclassified\"].append({\n",
    "                            \"Commit SHA\": commit_sha,\n",
    "                            \"True Label\": true_label,\n",
    "                            \"Predicted\": final_pred,\n",
    "                            \"Patch\": item.get(\"Patch\", \"\")\n",
    "                        })\n",
    "                        logger.warning(f\"Misclassification on commit {commit_sha}\")\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing commit {idx} ({commit_sha}): {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if results[\"y_true\"] and results[\"y_pred\"]:\n",
    "            metrics = calculate_metrics(results[\"y_true\"], results[\"y_pred\"])\n",
    "            print_metrics(metrics)\n",
    "            output_file = save_results(results, metrics, OUTPUT_DIR)\n",
    "            logger.info(f\"\\nClassification completed successfully. Results saved to {output_file}\")\n",
    "            \n",
    "            print(\"\\nSummary:\")\n",
    "            print(f\"Total commits processed: {len(results['y_true'])}\")\n",
    "            print(f\"Total misclassified: {len(results['misclassified'])}\")\n",
    "            print(f\"Success rate: {(1 - len(results['misclassified'])/len(results['y_true']))*100:.2f}%\")\n",
    "        else:\n",
    "            logger.error(\"No valid predictions were made\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in main execution: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Cleaning up resources...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
