{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configuration\n",
    "MAX_RETRIES = 5\n",
    "BASE_DELAY = 5\n",
    "MAX_DELAY = 120\n",
    "REQUEST_DELAY = 2\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable is required\")\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "def load_input_data(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Agent prompts\n",
    "DETECTOR_PROMPT = \"\"\"You are a specialized NPE detector. Analyze commits for NPE-related changes.\n",
    "Output format: {\"npe_found\": boolean, \"confidence\": float, \"reasoning\": \"string\"}\"\"\"\n",
    "\n",
    "CLASSIFIER_PROMPT = \"\"\"You are a code pattern classifier for NPE fixes.\n",
    "Output format: {\"is_npe_fix\": boolean, \"pattern_match\": float, \"patterns\": []}\"\"\"\n",
    "\n",
    "EVALUATOR_PROMPT = \"\"\"You are a senior reviewer making final NPE classifications.\n",
    "Output format: {\"final_decision\": \"NPE-Fixes\"/\"Not-NPE\", \"confidence\": float, \"feedback\": \"string\"}\"\"\"\n",
    "\n",
    "class NPEAgent:\n",
    "    def __init__(self, model, role, prompt):\n",
    "        self.model = model\n",
    "        self.role = role\n",
    "        self.prompt = prompt\n",
    "        self.last_request_time = 0\n",
    "    \n",
    "    def wait_for_rate_limit(self):\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        if time_since_last < REQUEST_DELAY:\n",
    "            time.sleep(REQUEST_DELAY - time_since_last)\n",
    "        self.last_request_time = time.time()\n",
    "    \n",
    "    def validate_json(self, text):\n",
    "        try:\n",
    "            start = text.find('{')\n",
    "            end = text.rfind('}') + 1\n",
    "            if start >= 0 and end > 0:\n",
    "                return json.loads(text[start:end])\n",
    "            return self.default_response()\n",
    "        except:\n",
    "            return self.default_response()\n",
    "    \n",
    "    def default_response(self):\n",
    "        defaults = {\n",
    "            \"detector\": {\"npe_found\": False, \"confidence\": 0.0, \"reasoning\": \"Error\"},\n",
    "            \"classifier\": {\"is_npe_fix\": False, \"pattern_match\": 0.0, \"patterns\": []},\n",
    "            \"evaluator\": {\"final_decision\": \"Not-NPE\", \"confidence\": 0.0, \"feedback\": \"Error\"}\n",
    "        }\n",
    "        return defaults.get(self.role, defaults[\"evaluator\"])\n",
    "    \n",
    "    def process(self, content, previous_results=None):\n",
    "        retries = 0\n",
    "        while retries < MAX_RETRIES:\n",
    "            try:\n",
    "                self.wait_for_rate_limit()\n",
    "                \n",
    "                prompt = f\"{self.prompt}\\n\\nRespond only in JSON format\\n\\n\"\n",
    "                if previous_results:\n",
    "                    prompt += f\"Previous: {json.dumps(previous_results)}\\nAnalyze: {content}\"\n",
    "                else:\n",
    "                    prompt += content\n",
    "\n",
    "                if retries > 0:\n",
    "                    delay = min(BASE_DELAY * (2 ** retries), MAX_DELAY)\n",
    "                    print(f\"Retrying in {delay} seconds... ({retries}/{MAX_RETRIES})\")\n",
    "                    time.sleep(delay)\n",
    "\n",
    "                generation_config = genai.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=500,\n",
    "                )\n",
    "                \n",
    "                response = self.model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=generation_config\n",
    "                )\n",
    "                return self.validate_json(response.text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                retries += 1\n",
    "                print(f\"Error in {self.role} (attempt {retries}/{MAX_RETRIES}): {e}\")\n",
    "                if retries < MAX_RETRIES:\n",
    "                    continue\n",
    "                return self.default_response()\n",
    "\n",
    "def multi_agent_classify(model, commit_message, patch, added_lines):\n",
    "    try:\n",
    "        detector = NPEAgent(model, \"detector\", DETECTOR_PROMPT)\n",
    "        classifier = NPEAgent(model, \"classifier\", CLASSIFIER_PROMPT)\n",
    "        evaluator = NPEAgent(model, \"evaluator\", EVALUATOR_PROMPT)\n",
    "        \n",
    "        content = f\"\"\"\n",
    "        Commit Message: {commit_message}\n",
    "        Patch: {patch}\n",
    "        Added Lines: {added_lines}\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Running detector...\")\n",
    "        detection_result = detector.process(content)\n",
    "        \n",
    "        print(\"Running classifier...\")\n",
    "        classification_result = classifier.process(content, detection_result)\n",
    "        \n",
    "        print(\"Running evaluator...\")\n",
    "        evaluation_result = evaluator.process(content, {\n",
    "            \"detection\": detection_result,\n",
    "            \"classification\": classification_result\n",
    "        })\n",
    "        \n",
    "        print(\"Running refined analysis...\")\n",
    "        refined_detection = detector.process(content, evaluation_result)\n",
    "        refined_classification = classifier.process(content, {\n",
    "            \"previous_detection\": detection_result,\n",
    "            \"previous_evaluation\": evaluation_result,\n",
    "            \"new_detection\": refined_detection\n",
    "        })\n",
    "        \n",
    "        final_result = evaluator.process(content, {\n",
    "            \"first_iteration\": evaluation_result,\n",
    "            \"refined_detection\": refined_detection,\n",
    "            \"refined_classification\": refined_classification\n",
    "        })\n",
    "        \n",
    "        return final_result.get(\"final_decision\", \"Not-NPE\")\n",
    "    except Exception as e:\n",
    "        print(f\"Classification error: {e}\")\n",
    "        return \"Not-NPE\"\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(f\"Starting analysis at {start_time}\")\n",
    "    \n",
    "    data = load_input_data(\"NPEPatches.json\")\n",
    "    if not data:\n",
    "        return\n",
    "    \n",
    "    results = {\n",
    "        \"y_true\": [], \n",
    "        \"y_pred\": [], \n",
    "        \"misclassified\": [],\n",
    "        \"start_time\": start_time.isoformat(),\n",
    "        \"end_time\": None\n",
    "    }\n",
    "    \n",
    "    total_items = len(data)\n",
    "    for idx, item in enumerate(data, 1):\n",
    "        print(f\"\\nProcessing item {idx}/{total_items}...\")\n",
    "        print(f\"Progress: {(idx/total_items)*100:.1f}%\")\n",
    "        \n",
    "        true_label = item[\"Category\"]\n",
    "        prediction = multi_agent_classify(\n",
    "            model,\n",
    "            item[\"Commit Message\"],\n",
    "            item[\"Patch\"],\n",
    "            item[\"Added Lines\"]\n",
    "        )\n",
    "        \n",
    "        results[\"y_true\"].append(true_label)\n",
    "        results[\"y_pred\"].append(prediction)\n",
    "        \n",
    "        if prediction != true_label:\n",
    "            results[\"misclassified\"].append({\n",
    "                \"SHA\": item.get(\"Commit SHA\", \"N/A\"),\n",
    "                \"True\": true_label,\n",
    "                \"Predicted\": prediction,\n",
    "                \"Patch\": item[\"Patch\"]\n",
    "            })\n",
    "    \n",
    "    end_time = datetime.datetime.now()\n",
    "    results[\"end_time\"] = end_time.isoformat()\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(results[\"y_true\"], results[\"y_pred\"]),\n",
    "        \"precision\": precision_score(results[\"y_true\"], results[\"y_pred\"], \n",
    "                                  pos_label=\"NPE-Fixes\", zero_division=0),\n",
    "        \"recall\": recall_score(results[\"y_true\"], results[\"y_pred\"], \n",
    "                             pos_label=\"NPE-Fixes\", zero_division=0),\n",
    "        \"f1\": f1_score(results[\"y_true\"], results[\"y_pred\"], \n",
    "                      pos_label=\"NPE-Fixes\", zero_division=0)\n",
    "    }\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"results_{timestamp}.json\"\n",
    "    \n",
    "    with open(results_file, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"metrics\": metrics,\n",
    "            \"misclassified\": results[\"misclassified\"],\n",
    "            \"execution_time\": str(end_time - start_time)\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(\"\\nResults:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    print(f\"Misclassified: {len(results['misclassified'])}\")\n",
    "    print(f\"Total execution time: {end_time - start_time}\")\n",
    "    print(f\"Results saved to: {results_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
