{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mixtral-8x7B-32768 is an advanced large language model (LLM) created by Mistral AI\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import logging\n",
    "import time\n",
    "from json import JSONDecodeError\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('your_api_key_here')\n",
    "if not api_key:\n",
    "    raise ValueError(\"API_KEY environment variable is required\")\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"/root/workspace/npe_project/llm/Best NPE Examples.json\"\n",
    "OUTPUT_DIR = \"results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Rate limiting configuration\n",
    "RATE_LIMIT_DELAY = 2  # seconds between API calls\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load and validate JSON data from file\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        logger.info(f\"Successfully loaded {len(data)} records from {filepath}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Data file not found: {filepath}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Invalid JSON format in file: {filepath}\")\n",
    "        raise\n",
    "\n",
    "class NPEAgent:\n",
    "    def __init__(self, client, role, prompt):\n",
    "        self.client = client\n",
    "        self.role = role\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def process(self, content, previous_results=None):\n",
    "        try:\n",
    "            # Rate limiting\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "            \n",
    "            messages = [{\"role\": \"system\", \"content\": self.prompt}]\n",
    "            \n",
    "            # Format the user message\n",
    "            user_message = content if not previous_results else \\\n",
    "                f\"Previous analysis: {json.dumps(previous_results)}\\n\\nNew content: {content}\"\n",
    "            messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "            \n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=\"claude-3-sonnet\",\n",
    "                messages=messages,\n",
    "                temperature=0.1,\n",
    "                max_tokens=500,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            response_text = completion.choices[0].message.content\n",
    "            try:\n",
    "                return json.loads(response_text)\n",
    "            except JSONDecodeError:\n",
    "                logger.error(f\"Invalid JSON response from {self.role}: {response_text}\")\n",
    "                return self._get_default_response(\"Error parsing response\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in {self.role} processing: {str(e)}\")\n",
    "            return self._get_default_response(f\"Error: {str(e)}\")\n",
    "\n",
    "    def _get_default_response(self, reason):\n",
    "        if self.role == \"evaluator\":\n",
    "            return {\n",
    "                \"final_decision\": \"Not-NPE\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"feedback\": reason\n",
    "            }\n",
    "        return {\n",
    "            \"npe_found\": False,\n",
    "            \"confidence\": 0.0,\n",
    "            \"reasoning\": reason\n",
    "        }\n",
    "\n",
    "def multi_agent_classify(client, commit_message, patch, added_lines):\n",
    "    try:\n",
    "        detector = NPEAgent(client, \"detector\", \"\"\"\n",
    "            You are a specialized NullPointerException (NPE) detector. \n",
    "            Analyze the given code changes and respond with a JSON object containing:\n",
    "            {\n",
    "                \"npe_found\": boolean,\n",
    "                \"confidence\": float between 0-1,\n",
    "                \"reasoning\": string explanation\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        classifier = NPEAgent(client, \"classifier\", \"\"\"\n",
    "            You are a code pattern classifier specializing in NPE fixes.\n",
    "            Analyze the code and respond with a JSON object containing:\n",
    "                \"is_npe_fix\": boolean,\n",
    "                \"pattern_match\": float between 0-1,\n",
    "                \"identified_patterns\": array of strings\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        evaluator = NPEAgent(client, \"evaluator\", \"\"\"\n",
    "            You are a senior code reviewer evaluating NPE fix classifications.\n",
    "            Review the analysis and respond with a JSON object containing:\n",
    "            {\n",
    "                \"final_decision\": string (\"NPE-Fixes\" or \"Not-NPE\"),\n",
    "                \"confidence\": float between 0-1,\n",
    "                \"feedback\": string explanation\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        content = {\n",
    "            \"commit_message\": commit_message,\n",
    "            \"patch\": patch,\n",
    "            \"added_lines\": added_lines\n",
    "        }\n",
    "        \n",
    "        detection_result = detector.process(json.dumps(content))\n",
    "        if not isinstance(detection_result, dict):\n",
    "            logger.warning(f\"Invalid detection result format: {detection_result}\")\n",
    "            return \"Not-NPE\"\n",
    "            \n",
    "        classification_result = classifier.process(json.dumps(content), detection_result)\n",
    "        if not isinstance(classification_result, dict):\n",
    "            logger.warning(f\"Invalid classification result format: {classification_result}\")\n",
    "            return \"Not-NPE\"\n",
    "            \n",
    "        final_result = evaluator.process(json.dumps(content), {\n",
    "            \"detection\": detection_result,\n",
    "            \"classification\": classification_result\n",
    "        })\n",
    "        \n",
    "        if isinstance(final_result, dict) and \"final_decision\" in final_result:\n",
    "            return final_result[\"final_decision\"]\n",
    "        return \"Not-NPE\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in multi-agent classification: {str(e)}\")\n",
    "        return \"Not-NPE\"\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"precision\": precision_score(y_true, y_pred, pos_label=\"NPE-Fixes\"),\n",
    "            \"recall\": recall_score(y_true, y_pred, pos_label=\"NPE-Fixes\"),\n",
    "            \"f1\": f1_score(y_true, y_pred, pos_label=\"NPE-Fixes\"),\n",
    "            \"confusion_matrix\": {\n",
    "                \"true_negatives\": int(tn),\n",
    "                \"false_positives\": int(fp),\n",
    "                \"false_negatives\": int(fn),\n",
    "                \"true_positives\": int(tp)\n",
    "            },\n",
    "            \"fpr\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "            \"fnr\": fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating metrics: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print(\"\\nClassification Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"\\nAccuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"False Positive Rate: {metrics['fpr']:.4f}\")\n",
    "    print(f\"False Negative Rate: {metrics['fnr']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = metrics['confusion_matrix']\n",
    "    print(f\"True Negatives: {cm['true_negatives']}\")\n",
    "    print(f\"False Positives: {cm['false_positives']}\")\n",
    "    print(f\"False Negatives: {cm['false_negatives']}\")\n",
    "    print(f\"True Positives: {cm['true_positives']}\")\n",
    "\n",
    "def save_results(results, metrics, output_dir):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(output_dir, f\"classification_results_{timestamp}.json\")\n",
    "    \n",
    "    full_results = {\n",
    "        \"metrics\": metrics,\n",
    "        \"misclassified_commits\": results[\"misclassified\"],\n",
    "        \"run_timestamp\": timestamp,\n",
    "        \"total_commits_processed\": len(results[\"y_true\"]),\n",
    "        \"total_misclassified\": len(results[\"misclassified\"])\n",
    "    }\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(full_results, f, indent=2)\n",
    "    logger.info(f\"Results saved to {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        client = Groq(api_key=api_key)\n",
    "        results = {\"y_true\": [], \"y_pred\": [], \"misclassified\": []}\n",
    "        \n",
    "        data = load_data(DATA_PATH)\n",
    "        total_commits = len(data)\n",
    "        logger.info(f\"Processing {total_commits} commits...\")\n",
    "        \n",
    "        for idx, item in enumerate(data, 1):\n",
    "            try:\n",
    "                logger.info(f\"Processing commit {idx}/{total_commits}\")\n",
    "                if idx > 1:\n",
    "                    time.sleep(1)\n",
    "                \n",
    "                true_label = item[\"Category\"]\n",
    "                final_pred = multi_agent_classify(\n",
    "                    client,\n",
    "                    item.get(\"Commit Message\", \"\"),\n",
    "                    item.get(\"Patch\", \"\"),\n",
    "                    item.get(\"Added Lines\", \"\")\n",
    "                )\n",
    "                \n",
    "                results[\"y_true\"].append(true_label)\n",
    "                results[\"y_pred\"].append(final_pred)\n",
    "                \n",
    "                if final_pred != true_label:\n",
    "                    results[\"misclassified\"].append({\n",
    "                        \"Commit SHA\": item.get(\"Commit SHA\", \"Unknown\"),\n",
    "                        \"True Label\": true_label,\n",
    "                        \"Predicted\": final_pred,\n",
    "                        \"Patch\": item.get(\"Patch\", \"\")\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing commit {idx}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if results[\"y_true\"] and results[\"y_pred\"]:\n",
    "            metrics = calculate_metrics(results[\"y_true\"], results[\"y_pred\"])\n",
    "            print_metrics(metrics)\n",
    "            output_file = save_results(results, metrics, OUTPUT_DIR)\n",
    "            logger.info(\"Classification completed successfully\")\n",
    "        else:\n",
    "            logger.error(\"No valid predictions were made\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in main execution: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Cleaning up resources...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"DATA_PATH\": \"/root/workspace/npe_project/llm/Best NPE Examples.json\",\n",
    "    \"OUTPUT_DIR\": \"results\",\n",
    "    \"MODEL\": \"claude-3-sonnet\",\n",
    "    \"RATE_LIMIT_DELAY\": 2,\n",
    "    \"MAX_TOKENS\": 500,\n",
    "    \"TEMPERATURE\": 0.1\n",
    "}\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('npe_classification.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class CommitData:\n",
    "    \"\"\"Data structure for commit information.\"\"\"\n",
    "    sha: str\n",
    "    message: str\n",
    "    patch: str\n",
    "    added_lines: str\n",
    "    category: str\n",
    "\n",
    "class NPEAgent:\n",
    "    \"\"\"Base agent class for NPE analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: Anthropic, role: str, prompt: str):\n",
    "        self.client = client\n",
    "        self.role = role\n",
    "        self.prompt = prompt\n",
    "        \n",
    "    def process(self, \n",
    "               content: Dict[str, Any], \n",
    "               previous_results: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Process commit data and return analysis results.\"\"\"\n",
    "        try:\n",
    "            time.sleep(CONFIG[\"RATE_LIMIT_DELAY\"])\n",
    "            \n",
    "            # Prepare message\n",
    "            user_message = (\n",
    "                f\"Previous analysis: {json.dumps(previous_results)}\\n\\n\"\n",
    "                f\"New content: {json.dumps(content)}\"\n",
    "            ) if previous_results else json.dumps(content)\n",
    "            \n",
    "            # Get completion from Claude\n",
    "            completion = self.client.messages.create(\n",
    "                model=CONFIG[\"MODEL\"],\n",
    "                system=self.prompt,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                }],\n",
    "                temperature=CONFIG[\"TEMPERATURE\"],\n",
    "                max_tokens=CONFIG[\"MAX_TOKENS\"],\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            return json.loads(completion.content[0].text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in {self.role} processing: {str(e)}\")\n",
    "            return self._get_default_response(str(e))\n",
    "    \n",
    "    def _get_default_response(self, reason: str) -> Dict[str, Any]:\n",
    "        \"\"\"Return default response in case of errors.\"\"\"\n",
    "        if self.role == \"evaluator\":\n",
    "            return {\n",
    "                \"final_decision\": \"Not-NPE\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"feedback\": reason\n",
    "            }\n",
    "        return {\n",
    "            \"npe_found\": False,\n",
    "            \"confidence\": 0.0,\n",
    "            \"reasoning\": reason\n",
    "        }\n",
    "\n",
    "class NPEClassificationSystem:\n",
    "    \"\"\"Main classification system coordinating multiple agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.agents = self._initialize_agents()\n",
    "        \n",
    "    def _initialize_agents(self) -> Dict[str, NPEAgent]:\n",
    "        \"\"\"Initialize the multi-agent system.\"\"\"\n",
    "        return {\n",
    "            \"detector\": NPEAgent(\n",
    "                self.client,\n",
    "                \"detector\",\n",
    "                \"\"\"You are a specialized NullPointerException (NPE) detector. \n",
    "                Analyze the given code changes and identify potential NPE-related issues.\"\"\"\n",
    "            ),\n",
    "            \"classifier\": NPEAgent(\n",
    "                self.client,\n",
    "                \"classifier\",\n",
    "                \"\"\"You are a code pattern classifier specializing in NPE fixes.\n",
    "                Analyze the code and identify specific NPE fix patterns.\"\"\"\n",
    "            ),\n",
    "            \"evaluator\": NPEAgent(\n",
    "                self.client,\n",
    "                \"evaluator\",\n",
    "                \"\"\"You are a senior code reviewer evaluating NPE fix classifications.\n",
    "                Review the previous analyses and make a final determination.\"\"\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def classify_commit(self, commit: CommitData) -> str:\n",
    "        \"\"\"Classify a single commit using the multi-agent system.\"\"\"\n",
    "        try:\n",
    "            content = {\n",
    "                \"commit_message\": commit.message,\n",
    "                \"patch\": commit.patch,\n",
    "                \"added_lines\": commit.added_lines\n",
    "            }\n",
    "            \n",
    "            # Multi-stage analysis\n",
    "            detection = self.agents[\"detector\"].process(content)\n",
    "            classification = self.agents[\"classifier\"].process(content, detection)\n",
    "            final_result = self.agents[\"evaluator\"].process(\n",
    "                content,\n",
    "                {\"detection\": detection, \"classification\": classification}\n",
    "            )\n",
    "            \n",
    "            return final_result.get(\"final_decision\", \"Not-NPE\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error classifying commit {commit.sha}: {str(e)}\")\n",
    "            return \"Not-NPE\"\n",
    "\n",
    "def load_data(filepath: str) -> List[CommitData]:\n",
    "    \"\"\"Load and parse commit data from JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        commits = [\n",
    "            CommitData(\n",
    "                sha=item.get(\"Commit SHA\", \"Unknown\"),\n",
    "                message=item.get(\"Commit Message\", \"\"),\n",
    "                patch=item.get(\"Patch\", \"\"),\n",
    "                added_lines=item.get(\"Added Lines\", \"\"),\n",
    "                category=item[\"Category\"]\n",
    "            )\n",
    "            for item in data\n",
    "        ]\n",
    "        \n",
    "        logger.info(f\"Loaded {len(commits)} commits from {filepath}\")\n",
    "        return commits\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        # Initialize\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"ANTHROPIC_API_KEY environment variable is required\")\n",
    "        \n",
    "        classifier = NPEClassificationSystem(api_key)\n",
    "        \n",
    "        # Process commits\n",
    "        commits = load_data(CONFIG[\"DATA_PATH\"])\n",
    "        results = {\n",
    "            \"y_true\": [],\n",
    "            \"y_pred\": [],\n",
    "            \"misclassified\": []\n",
    "        }\n",
    "        \n",
    "        for idx, commit in enumerate(commits, 1):\n",
    "            logger.info(f\"Processing commit {idx}/{len(commits)}\")\n",
    "            prediction = classifier.classify_commit(commit)\n",
    "            \n",
    "            results[\"y_true\"].append(commit.category)\n",
    "            results[\"y_pred\"].append(prediction)\n",
    "            \n",
    "            if prediction != commit.category:\n",
    "                results[\"misclassified\"].append({\n",
    "                    \"sha\": commit.sha,\n",
    "                    \"true_label\": commit.category,\n",
    "                    \"predicted\": prediction\n",
    "                })\n",
    "        \n",
    "        # Calculate and save metrics\n",
    "        metrics = calculate_metrics(results[\"y_true\"], results[\"y_pred\"])\n",
    "        save_results(results, metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
